{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96621675-d8b8-45d8-b30b-7bfad52701b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "from typing import Dict\n",
    "\n",
    "import ase\n",
    "import ase.io\n",
    "from ase import units\n",
    "from ase.md.langevin import Langevin\n",
    "from ase.md.velocitydistribution import Stationary, ZeroRotation, MaxwellBoltzmannDistribution\n",
    "from ase.calculators.calculator import Calculator, all_changes\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pylab as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c0c2f96-55df-4f45-a933-4c1b42704db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualReadoutMACE(nn.Module):\n",
    "    \"\"\"\n",
    "    Finalna wersja klasy:\n",
    "    1. Poprawnie rejestruje hak.\n",
    "    2. Optymalizuje metodę forward.\n",
    "    3. Inicjalizuje wagi głowy \"delta\" zerami dla poprawnego startu.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_mace_model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.features = None\n",
    "        self.mace_model = base_mace_model\n",
    "\n",
    "        print(\"Zamrażanie parametrów całego modelu bazowego MACE...\")\n",
    "        for param in self.mace_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.mace_model.eval()\n",
    "\n",
    "        if not hasattr(self.mace_model, 'readouts') or not isinstance(self.mace_model.readouts, nn.ModuleList) or len(self.mace_model.readouts) == 0:\n",
    "            raise AttributeError(\"Nie znaleziono modułu 'readouts' w modelu MACE lub jest on pusty.\")\n",
    "\n",
    "        self.base_readout_layer = self.mace_model.readouts[0]\n",
    "\n",
    "        num_features = self.base_readout_layer.linear.irreps_in.dim\n",
    "        print(f\"Wykryto {num_features} cech wejściowych do głowy (readout).\")\n",
    "\n",
    "        self.delta_readout = nn.Linear(num_features, 1, bias=False)\n",
    "\n",
    "        # INICJALIZACJA WAG ZERAMI\n",
    "        torch.nn.init.zeros_(self.delta_readout.weight)\n",
    "        print(\"Wagi nowej głowy 'delta_readout' zostały zainicjalizowane zerami.\")\n",
    "\n",
    "        self.base_readout_layer.register_forward_hook(self._hook_fn)\n",
    "        print(\"Nowa głowa 'delta_readout' dodana. Hak poprawnie zarejestrowany.\")\n",
    "\n",
    "    def _hook_fn(self, module, input_data, output_data):\n",
    "        self.features = input_data[0]\n",
    "\n",
    "    def forward(self, data: Dict[str, torch.Tensor], compute_force: bool = False) -> Dict[str, torch.Tensor]:\n",
    "        if compute_force:\n",
    "            data[\"positions\"].requires_grad_(True)\n",
    "\n",
    "        base_output = self.mace_model(data, compute_force=False)\n",
    "        base_energy = base_output[\"energy\"]\n",
    "\n",
    "        if self.features is None:\n",
    "            raise RuntimeError(\"Hak nie przechwycił cech atomowych. Sprawdź strukturę modelu MACE.\")\n",
    "\n",
    "        delta_atomic_energies = self.delta_readout(self.features)\n",
    "        delta_energy = torch.sum(delta_atomic_energies, dim=-2)\n",
    "\n",
    "        self.features = None\n",
    "        final_energy = base_energy + delta_energy\n",
    "\n",
    "        output_data = {}\n",
    "        if compute_force:\n",
    "            forces = -torch.autograd.grad(\n",
    "                outputs=final_energy.sum(),\n",
    "                inputs=data[\"positions\"],\n",
    "                create_graph=False,\n",
    "                retain_graph=False,\n",
    "            )[0]\n",
    "            output_data[\"forces\"] = forces.detach()\n",
    "\n",
    "        output_data[\"energy\"] = final_energy.detach()\n",
    "        return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3c4186-cd3b-4201-84b5-1756f54b13f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wczytywanie modelu bazowego z: ./MACE-MP_small.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krystynasyty/myenv/lib/python3.12/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuequivariance or cuequivariance_torch is not available. Cuequivariance acceleration will be disabled.\n",
      "Zamrażanie parametrów całego modelu bazowego MACE...\n",
      "Wykryto 128 cech wejściowych do głowy (readout).\n",
      "Wagi nowej głowy 'delta_readout' zostały zainicjalizowane zerami.\n",
      "Nowa głowa 'delta_readout' dodana. Hak poprawnie zarejestrowany.\n",
      "\n",
      "============================================================\n",
      "      Podsumowanie finalnego modelu 'DualReadoutMACE'\n",
      "============================================================\n",
      "DualReadoutMACE(\n",
      "  (mace_model): ScaleShiftMACE(\n",
      "    (node_embedding): LinearNodeEmbeddingBlock(\n",
      "      (linear): Linear(89x0e -> 128x0e | 11392 weights)\n",
      "    )\n",
      "    (radial_embedding): RadialEmbeddingBlock(\n",
      "      (bessel_fn): BesselBasis(r_max=6.0, num_basis=10, trainable=False)\n",
      "      (cutoff_fn): PolynomialCutoff(p=5.0, r_max=6.0)\n",
      "    )\n",
      "    (spherical_harmonics): SphericalHarmonics()\n",
      "    (atomic_energies_fn): AtomicEnergiesBlock(energies=[[-3.6672, -1.3321, -3.4821, -4.7367, -7.7249, -8.4056, -7.3601, -7.2846, -4.8965, 0.0000, -2.7594, -2.8140, -4.8469, -7.6948, -6.9633, -4.6726, -2.8117, -0.0626, -2.6176, -5.3905, -7.8858, -10.2684, -8.6651, -9.2331, -8.3050, -7.0490, -5.5774, -5.1727, -3.2521, -1.2902, -3.5271, -4.7085, -3.9765, -3.8862, -2.5185, 6.7669, -2.5635, -4.9380, -10.1498, -11.8469, -12.1389, -8.7917, -8.7869, -7.7809, -6.8500, -4.8910, -2.0634, -0.6396, -2.7887, -3.8186, -3.5871, -2.8804, -1.6356, 9.8467, -2.7653, -4.9910, -8.9337, -8.7356, -8.0190, -8.2515, -7.5917, -8.1697, -13.5927, -18.5175, -7.6474, -8.1230, -7.6078, -6.8503, -7.8269, -3.5848, -7.4554, -12.7963, -14.1081, -9.3549, -11.3875, -9.6219, -7.3244, -5.3047, -2.3801, 0.2495, -2.3240, -3.7300, -3.4388, -5.0629, -11.0246, -12.2656, -13.8556, -14.9331, -15.2828]])\n",
      "    (interactions): ModuleList(\n",
      "      (0-1): 2 x RealAgnosticResidualInteractionBlock(\n",
      "        (linear_up): Linear(128x0e -> 128x0e | 16384 weights)\n",
      "        (conv_tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e+1x3o -> 128x0e+128x1o+128x2e+128x3o | 512 paths | 512 weights)\n",
      "        (conv_tp_weights): FullyConnectedNet[10, 64, 64, 64, 512]\n",
      "        (linear): Linear(128x0e+128x1o+128x2e+128x3o -> 128x0e+128x1o+128x2e+128x3o | 65536 weights)\n",
      "        (skip_tp): FullyConnectedTensorProduct(128x0e x 89x0e -> 128x0e | 1458176 paths | 1458176 weights)\n",
      "        (reshape): reshape_irreps()\n",
      "      )\n",
      "    )\n",
      "    (products): ModuleList(\n",
      "      (0-1): 2 x EquivariantProductBasisBlock(\n",
      "        (symmetric_contractions): SymmetricContraction(\n",
      "          (contractions): ModuleList(\n",
      "            (0): Contraction(\n",
      "              (contractions_weighting): ModuleList(\n",
      "                (0-1): 2 x GraphModule()\n",
      "              )\n",
      "              (contractions_features): ModuleList(\n",
      "                (0-1): 2 x GraphModule()\n",
      "              )\n",
      "              (weights): ParameterList(\n",
      "                  (0): Parameter containing: [torch.float32 of size 89x4x128]\n",
      "                  (1): Parameter containing: [torch.float32 of size 89x1x128]\n",
      "              )\n",
      "              (graph_opt_main): GraphModule()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (linear): Linear(128x0e -> 128x0e | 16384 weights)\n",
      "      )\n",
      "    )\n",
      "    (readouts): ModuleList(\n",
      "      (0): LinearReadoutBlock(\n",
      "        (linear): Linear(128x0e -> 1x0e | 128 weights)\n",
      "      )\n",
      "      (1): NonLinearReadoutBlock(\n",
      "        (linear_1): Linear(128x0e -> 16x0e | 2048 weights)\n",
      "        (non_linearity): Activation [x] (16x0e -> 16x0e)\n",
      "        (linear_2): Linear(16x0e -> 1x0e | 16 weights)\n",
      "      )\n",
      "    )\n",
      "    (scale_shift): ScaleShiftBlock(scale=0.8042, shift=0.1641)\n",
      "  )\n",
      "  (base_readout_layer): LinearReadoutBlock(\n",
      "    (linear): Linear(128x0e -> 1x0e | 128 weights)\n",
      "  )\n",
      "  (delta_readout): Linear(in_features=128, out_features=1, bias=False)\n",
      ")\n",
      "------------------------------------------------------------\n",
      "\n",
      "Całkowita liczba parametrów: 3,847,824\n",
      "Liczba trenowalnych parametrów: 128\n",
      "\n",
      "Szczegóły parametrów trenowalnych:\n",
      "  - Warstwa: 'delta_readout.weight' | Rozmiar: torch.Size([1, 128]) | Status: Trenowalna\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # --- 1. Wczytaj modele ---\n",
    "    MODEL_PATH = './MACE-MP_small.model'\n",
    "    print(f\"Wczytywanie modelu bazowego z: {MODEL_PATH}\")\n",
    "    base_model = torch.load(MODEL_PATH, map_location=device, weights_only=False).float()\n",
    "    dual_model = DualReadoutMACE(base_model)\n",
    "\n",
    "    # --- 2. Wydrukuj podsumowanie finalnego modelu ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"      Podsumowanie finalnego modelu 'DualReadoutMACE'\")\n",
    "    print(\"=\"*60)\n",
    "    print(dual_model)\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    # --- 3. Wydrukuj szczegóły dotyczące parametrów trenowalnych vs zamrożonych ---\n",
    "    total_params = sum(p.numel() for p in dual_model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in dual_model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(f\"\\nCałkowita liczba parametrów: {total_params:,}\")\n",
    "    print(f\"Liczba trenowalnych parametrów: {trainable_params:,}\")\n",
    "    print(\"\\nSzczegóły parametrów trenowalnych:\")\n",
    "    found_trainable = False\n",
    "    for name, param in dual_model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f\"  - Warstwa: '{name}' | Rozmiar: {param.shape} | Status: Trenowalna\")\n",
    "            found_trainable = True\n",
    "    \n",
    "    if not found_trainable:\n",
    "        print(\"  - Brak trenowalnych parametrów.\")\n",
    "        \n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4fe66f-2a59-43b4-b775-d0244d1ba778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
